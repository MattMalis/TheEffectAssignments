---
title: "Chapter 15 Coding Homework"
author: "Nick Huntington-Klein"
date: "Updated `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(Statamarkdown)
```

Follow the below instructions and turn in both your code and results:

1. Create a data set with 1000 observations and four variables. Note that for A and B the values specified are the random-number-generation defaults in all languages so you shouldn't need to change anything. Also note that there are many different ways to make C and D, all are valid if they work:

- A, which is normally distributed with mean 0 and standard deviation 1
- B, which is uniformly distributed from 0 to 1
- C, which is equal to 1 (or if you prefer, True) with probability .4 and 0 (or if you prefer, False) with probability .6
- D, which is equal to 2 with probability .5, 1 with probability .3, and 0 with probability .2.

*Tip*: try tabulating the proportion of each value you get in your data for variables C and D to check if you did it properly. "Checking afterwards if you did it properly" is a very basic but far too often overlooked statistical-coding skill.

*Language-specific instructions*: 

- In Stata, you'll want to `clear` your data before doing this or else you'll get errors if you rerun your code.
- In R or Python, name the data set you create `d`. Also, only write the number 1000 (for 1000 observations) *once* in your code by assigning it to a variable outside your data set `N`, and referring to `N` instead of 1000 when generating each variable in your data set.


2. Generate a data set with 1000 observations with the following variables:

- eps, which is normally distributed
- nu, which is normally distributed
- W, which is 0 (or False) with probability .5 and 1 (True) with probability .5
- D, our treatment variable, which is 1 if nu + (W - .5) is positive, and 0 if it's negative
- Y, our outcome variable, which is X + W + eps.

3. Write out the causal diagram paths implied by the data generating process you made in the last question (you only need to write out the direct arrows between two variables; there are five such arrows).

4. Take the data-generating code from step 2. Change the way that Y is generated by adding coefficients to some of the variables. So Y is now b1*X + b2*W + eps. Then put it inside a function called `create_data` that lets you set N, b1, and b2 and leaves you with the created data set. In R and Python set the defaults to 1000, 1, and 0 respectively.

*Language-specific instructions*: 

- In Stata, you'll need to refer to b1 and b2 using the local-variable indicators instead of just directly. See examples in the textbook chapter. And you can set defaults if you want too, but you'll either need to use the `syntax` function for setting up your function, which we didn't cover, or do something like check if the option is specified inside of your function, and fill it in if it isn't.

5. Create a new function called `est_function` that runs `create_data` to get some data, then runs a linear regression of Y on X, and returns the coefficient on D. `est_function()` should also take N, b1, and b2 as arguments, and pass them along to `create_data`.

*Language-specific instructions*: 

- In Stata, just run the entire regression and end the function there (you don't even need the `estimates store' step if the next thing you do after calling `est_function` is get the coefficient) rather than trying to return the coefficient. This will be easier.

6. Set your random seed to 5000. Then run `est_function` 1000 times with `N=1000, b1=1, b2=0`, storing all the results. Then show the mean and standard deviation of the estimates across the 1000 iterations. Comment on whether this estimator seems to work well. (and save your mean and SD results - we'll refer back to them later)

7. Now we're going to rerun the simulation but with b2 set to 1 instead of 0. This will help us test how well our estimator will hold up when we break one of its assumptions. Comment on what assumption we are breaking. Rerun your code from step 7 but with b2 = 1. Comment on whether the estimator performs well with this broken assumption.

8. Create new estimation functions `est_control()` and `est_interact()`. Each of themt modifies the `est_function()` function to control for W. `est_control` simply adds W as a control, so you regress Y on D and W and return the coefficient on D. `est_interact` controls for W by *fully interacting* it with D. In other words, you'll regress Y on D, W, and D times W. Then, estimate the *marginal effect at the mean* (remember Chapter 13) as (coefficient on D) + (average of W)x(coefficient on the interaction), and return that marginal effect at the mean. Set your seed to 5000 and run 1000 iterations of `est_control()` and 1000 of  `est_interact()` (both with b2 = 1). Comment on whether a fully-interacted model still works to get the right effect, and if both models work well, whether one has better precision than the other.

9. Modify `est_control` to return 1 if the coefficient on D is statistically significant at the 95% level, and 0 otherwise. Then, try running it with different sample sizes (500 iterations per sample size you try) to find the minimum sample size necessary to get 90% power if b1 = .5 and b2 = .5. Report what minimum sample size is. You don't have to get it exactly - finding the smallest multiple of 100 that gives 90% power or better is close enough.

Tip: Not sure what range of sample sizes to try? Search around with a smaller number of iterations (maybe 100 instead of 500?) until you get numbers that look sort of like 90%, then increase the number of iterations to see if it holds up.

*Language-specific instructions*: 

- In Stata, this will mostly require modifying your iteration loop (or iteration function, if you wrote one), rather than modifying `est_control`.

10. Now, keep the sample size at 500, and find the minimum detectable effect (b1) to get 90% power when b2 = .5.

11. Double b2 to be 1 instead of .5 and find the minimum detectable effect again. Does this change the minimum detectable effect? 